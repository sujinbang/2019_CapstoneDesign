{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85831db",
   "metadata": {},
   "source": [
    "# LSTM을 활용한 불쾌지수 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0389cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf73bebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810aae46",
   "metadata": {},
   "source": [
    "- 랜덤에 의해 똑같은 결과를 재현하도록 시드 설정\n",
    "- 하이퍼파라미터를 튜닝하기 위한 용도\n",
    "- Neural net의 초기값을 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "216df033",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0a41f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "def data_standardization(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.mean()) / x_np.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c130e11",
   "metadata": {},
   "source": [
    "- 너무 작거나 너무 큰 값이 학습을 방해하는 것을 방지하고자 정규화한다\n",
    "- x가 양수라는 가정하에 최소값과 최대값을 이용하여 0~1사이의 값으로 변환\n",
    "- Min-Max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3383c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7)\n",
    "    # 1e-7은 0으로 나누는 오류 예방차원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e5e084",
   "metadata": {},
   "source": [
    "- 정규화된 값을 원래의 값으로 되돌린다\n",
    "- 정규화하기 이전의 org_x값과 되돌리고 싶은 x를 입력하면 역정규화된 값을 리턴한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd4d6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_min_max_scaling(org_x, x):\n",
    "    org_x_np = np.asarray(org_x)\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e91490a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "input_data_column_cnt = 3  # 입력데이터의 컬럼 개수(Variable 개수)\n",
    "output_data_column_cnt = 1  # 결과데이터의 컬럼 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bdd7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 30  # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
    "rnn_cell_hidden_dim = 20  # 각 셀의 (hidden)출력 크기\n",
    "forget_bias = 1.0  # 망각편향(기본값 1.0)\n",
    "num_stacked_layers = 1  # stacked LSTM layers 개수\n",
    "keep_prob = 1.0  # dropout할 때 keep할 비율\n",
    "\n",
    "epoch_num = 1000  # epoch 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
    "learning_rate = 0.01  # 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421899c",
   "metadata": {},
   "source": [
    "- 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c23c0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 49 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   1970년   32 non-null     float64\n",
      " 1   1971년   32 non-null     float64\n",
      " 2   1972년   32 non-null     float64\n",
      " 3   1973년   32 non-null     float64\n",
      " 4   1974년   32 non-null     float64\n",
      " 5   1975년   32 non-null     float64\n",
      " 6   1976년   32 non-null     float64\n",
      " 7   1977년   32 non-null     float64\n",
      " 8   1978년   32 non-null     float64\n",
      " 9   1979년   32 non-null     float64\n",
      " 10  1980년   32 non-null     float64\n",
      " 11  1981년   32 non-null     float64\n",
      " 12  1982년   32 non-null     float64\n",
      " 13  1983년   32 non-null     float64\n",
      " 14  1984년   32 non-null     float64\n",
      " 15  1985년   32 non-null     float64\n",
      " 16  1986년   32 non-null     float64\n",
      " 17  1987년   32 non-null     float64\n",
      " 18  1988년   32 non-null     float64\n",
      " 19  1989년   32 non-null     float64\n",
      " 20  1990년   32 non-null     float64\n",
      " 21  1991년   32 non-null     float64\n",
      " 22  1992년   32 non-null     float64\n",
      " 23  1993년   32 non-null     float64\n",
      " 24  1994년   32 non-null     float64\n",
      " 25  1995년   32 non-null     float64\n",
      " 26  1996년   32 non-null     float64\n",
      " 27  1997년   32 non-null     float64\n",
      " 28  1998년   32 non-null     float64\n",
      " 29  1999년   32 non-null     float64\n",
      " 30  2000년   32 non-null     float64\n",
      " 31  2001년   32 non-null     float64\n",
      " 32  2002년   32 non-null     float64\n",
      " 33  2003년   32 non-null     float64\n",
      " 34  2004년   32 non-null     float64\n",
      " 35  2005년   32 non-null     float64\n",
      " 36  2006년   32 non-null     float64\n",
      " 37  2007년   32 non-null     float64\n",
      " 38  2008년   32 non-null     float64\n",
      " 39  2009년   32 non-null     float64\n",
      " 40  2010년   32 non-null     float64\n",
      " 41  2011년   32 non-null     float64\n",
      " 42  2012년   32 non-null     float64\n",
      " 43  2013년   32 non-null     float64\n",
      " 44  2014년   32 non-null     float64\n",
      " 45  2015년   32 non-null     float64\n",
      " 46  2016년   32 non-null     float64\n",
      " 47  2017년   32 non-null     float64\n",
      " 48  2018년   32 non-null     float64\n",
      "dtypes: float64(49)\n",
      "memory usage: 12.4 KB\n",
      "temp_info.shape:  (31, 49)\n",
      "temp_info[0]:  [69.980751 69.980751 75.260082 74.034206 77.870322 77.630576 74.089535\n",
      " 76.9124   79.532534 73.02322  72.244858 78.3626   72.81536  80.387\n",
      " 77.179693 76.290872 79.212275 76.67416  77.881    72.72366  80.684936\n",
      " 71.346746 76.967772 72.061375 80.809174 78.883099 81.049924 81.472808\n",
      " 77.221764 68.84226  78.126776 79.722473 76.272413 75.12945  77.631521\n",
      " 76.9926   78.1727   79.32949  77.295306 75.6295   78.250971 76.383725\n",
      " 79.926912 78.806104 80.9663   77.826205 77.4873   81.6726   83.967272]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_1492\\1616782163.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  temp_info = raw_dataframe.values[1:].astype(np.float)  # 기온 자료를 부동소수점형으로 변환\n"
     ]
    }
   ],
   "source": [
    "stock_file_name = 'DiscomfortIndex.csv'  # 부산광역시 기온 자료\n",
    "encoding = 'euc-kr'  # 문자 인코딩 방식 설정\n",
    "raw_dataframe = pd.read_csv(stock_file_name, encoding=encoding)  # 판다스이용 csv파일 로딩\n",
    "raw_dataframe.info()  # 데이터 정보 출력\n",
    "\n",
    "temp_info = raw_dataframe.values[1:].astype(np.float)  # 기온 자료를 부동소수점형으로 변환\n",
    "print(\"temp_info.shape: \", temp_info.shape)\n",
    "print(\"temp_info[0]: \", temp_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b8f6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "# 데이터 정규화\n",
    "\n",
    "norm_temp = min_max_scaling(temp_info)  # 기온 데이터 정규화 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb11f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  (31, 49)\n",
      "x[0]:  [0.32041762 0.32041762 0.57693175 0.51736842 0.70375908 0.69211021\n",
      " 0.52005677 0.6572152  0.78452327 0.46824625 0.43042691 0.72767807\n",
      " 0.45814667 0.82604038 0.67020254 0.62701617 0.7689624  0.64563951\n",
      " 0.70427791 0.45369112 0.84051661 0.3867891  0.65990564 0.42151176\n",
      " 0.84655313 0.75296827 0.85825079 0.87879803 0.6722467  0.26510019\n",
      " 0.71621976 0.79375209 0.62611927 0.57058455 0.69215613 0.66111199\n",
      " 0.71845114 0.77465769 0.67581999 0.59488117 0.7222542  0.63152774\n",
      " 0.80368545 0.74922721 0.85418763 0.70161551 0.68514866 0.8885056\n",
      " 1.        ]\n",
      "x[-1]:  [0.33186348 0.33186348 0.42451914 0.68012127 0.56924337 0.67211434\n",
      " 0.46585512 0.45990684 0.62492385 0.49595329 0.37099234 0.50020356\n",
      " 0.59263824 0.61107957 0.65712002 0.66225255 0.51277969 0.53620526\n",
      " 0.6217383  0.55470174 0.65336836 0.54938374 0.52642151 0.42107588\n",
      " 0.73445829 0.66332956 0.59996255 0.58495457 0.55179786 0.6049652\n",
      " 0.64767342 0.61231055 0.49201977 0.47546896 0.59172079 0.54412799\n",
      " 0.64976806 0.64652479 0.5279224  0.55539403 0.66334196 0.59105756\n",
      " 0.6503312  0.7018601  0.56100322 0.60294325 0.68845656 0.5792808\n",
      " 0.75005613]\n",
      "====================================================================================================\n",
      "y[0]:  [1.]\n",
      "y[-1]:  [0.75005613]\n",
      "[[0.32041762 0.32041762 0.57693175 ... 0.68514866 0.8885056  1.        ]\n",
      " [0.27501897 0.27501897 0.6059706  ... 0.77613458 0.81765345 0.9687618 ]\n",
      " [0.37222707 0.37222707 0.61329821 ... 0.84408747 0.82069066 0.87930948]\n",
      " ...\n",
      " [0.32613574 0.32613574 0.08842682 ... 0.2468431  0.06225877 0.60653169]\n",
      " [0.20807546 0.20807546 0.1180907  ... 0.15939695 0.09281823 0.58797302]\n",
      " [0.16421609 0.16421609 0.18000274 ... 0.         0.27631497 0.53901212]] -> [0.75005613]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_1492\\2397506268.py:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is 0:\n"
     ]
    }
   ],
   "source": [
    "# 행은 그대로 두고 열을 우측에 붙여 합친다\n",
    "x = norm_temp\n",
    "print(\"x.shape: \", x.shape)\n",
    "print(\"x[0]: \", x[0])  # x의 첫 값\n",
    "print(\"x[-1]: \", x[-1])  # x의 마지막 값\n",
    "print(\"=\" * 100)  # 화면상 구분용\n",
    "\n",
    "y = x[:, [-1]]  # 타켓은 평균기온이다\n",
    "print(\"y[0]: \", y[0])  # y의 첫 값\n",
    "print(\"y[-1]: \", y[-1])  # y의 마지막 값\n",
    "\n",
    "dataX = []  # 입력으로 사용될 Sequence Data\n",
    "dataY = []  # 출력(타켓)으로 사용\n",
    "\n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i: i + seq_length]\n",
    "    _y = y[i + seq_length]  # 다음날의 평균기온(정답)\n",
    "    if i is 0:\n",
    "        print(_x, \"->\", _y)  # 첫번째 행만 출력해 봄\n",
    "    dataX.append(_x)  # dataX 리스트에 추가\n",
    "    dataY.append(_y)  # dataY 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69a05d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용/테스트용 데이터 생성\n",
    "# 전체 70%를 학습용 데이터로 사용\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "# 나머지(30%)를 테스트용 데이터로 사용\n",
    "test_size = len(dataY) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1115b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 잘라 학습용 데이터 생성\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    "\n",
    "# 데이터를 잘라 테스트용 데이터 생성\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bd68835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  Tensor(\"Placeholder_8:0\", shape=(?, 30, 3), dtype=float32)\n",
      "Y :  Tensor(\"Placeholder_9:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 플레이스홀더 생성\n",
    "# 입력 X, 출력 Y를 생성한다\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "X = tf.placeholder(shape=[None, seq_length, input_data_column_cnt], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "print(\"X : \", X)\n",
    "print(\"Y : \", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8942ffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets:  Tensor(\"Placeholder_10:0\", shape=(?, 1), dtype=float32)\n",
      "predictions:  Tensor(\"Placeholder_11:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
    "\n",
    "targets = tf.placeholder(shape=[None, 1], dtype = tf.float32)\n",
    "predictions = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "print(\"targets: \", targets)\n",
    "print(\"predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83bda580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델(LSTM 네트워크) 생성\n",
    "def lstm_cell():\n",
    "    # LSTM셀을 생성\n",
    "    # num_units: 각 Cell 출력 크기\n",
    "    # forget_bias:  to the biases of the forget gate\n",
    "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
    "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
    "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim,\n",
    "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
    "    if keep_prob < 1.0:\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "739394f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e9453b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v1' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m stackedRNNs \u001b[38;5;241m=\u001b[39m [lstm_cell() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_stacked_layers)]\n\u001b[0;32m      3\u001b[0m multi_cells \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcontrib\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mMultiRNNCell(stackedRNNs, state_is_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m num_stacked_layers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m lstm_cell()\n",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m stackedRNNs \u001b[38;5;241m=\u001b[39m [\u001b[43mlstm_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_stacked_layers)]\n\u001b[0;32m      3\u001b[0m multi_cells \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcontrib\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mMultiRNNCell(stackedRNNs, state_is_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m num_stacked_layers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m lstm_cell()\n",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36mlstm_cell\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlstm_cell\u001b[39m():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# LSTM셀을 생성\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# num_units: 각 Cell 출력 크기\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# state_is_tuple: False ==> they are concatenated along the column axis.\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     cell \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrib\u001b[49m\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mBasicLSTMCell(num_units\u001b[38;5;241m=\u001b[39mrnn_cell_hidden_dim,\n\u001b[0;32m     10\u001b[0m                                         forget_bias\u001b[38;5;241m=\u001b[39mforget_bias, state_is_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftsign)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keep_prob \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m     12\u001b[0m         cell \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcontrib\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mDropoutWrapper(cell, output_keep_prob\u001b[38;5;241m=\u001b[39mkeep_prob)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.compat.v1' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
    "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
    "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75a7eca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi_cells' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# RNN Cell(여기서는 LSTM셀임)들을 연결\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hypothesis, _states \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mdynamic_rnn(\u001b[43mmulti_cells\u001b[49m, X, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhypothesis: \u001b[39m\u001b[38;5;124m\"\u001b[39m, hypothesis)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 과거 여러 날짜의 기온 자료를 이용해서 다음날의 평균기온 1개를 예측 : MANY-TO-ONE model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multi_cells' is not defined"
     ]
    }
   ],
   "source": [
    "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
    "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "print(\"hypothesis: \", hypothesis)\n",
    "\n",
    "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
    "# 과거 여러 날짜의 기온 자료를 이용해서 다음날의 평균기온 1개를 예측 : MANY-TO-ONE model\n",
    "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f49d4cc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hypothesis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 손실함수 : 평균제곱오차\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(tf\u001b[38;5;241m.\u001b[39msquare(\u001b[43mhypothesis\u001b[49m \u001b[38;5;241m-\u001b[39m Y))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# AdamOptimizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mAdamOptimizer(learning_rate)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hypothesis' is not defined"
     ]
    }
   ],
   "source": [
    "# 손실함수 : 평균제곱오차\n",
    "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "# AdamOptimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate) # LSTM과 궁합 별로임\n",
    "\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# RMSE(Root Mean Square Error)\n",
    "# 제곱오차의 평균을 구하고 다시 제곱근을 구하면 평균 오차가 나온다\n",
    "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions))) # 아래 코드와 같다\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
    "\n",
    "train_error_summary = []  # 학습용 데이터의 오류를 중간 중간 기록한다\n",
    "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
    "test_predict = ''  # 테스트용데이터로 예측한 결과\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df8007da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run : model training\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun : model training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch_num):\n\u001b[1;32m----> 5\u001b[0m     _, _loss \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241m.\u001b[39mrun([train, loss], feed_dict\u001b[38;5;241m=\u001b[39m{X: trainX, Y: trainY})\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (epoch \u001b[38;5;241m==\u001b[39m epoch_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):  \u001b[38;5;66;03m# 100번째마다 또는 마지막 epoch인 경우\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# 학습용데이터로 rmse오차를 구한다\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         train_predict \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun(hypothesis, feed_dict\u001b[38;5;241m=\u001b[39m{X: trainX})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "# 학습한다\n",
    "start_time = datetime.datetime.now()  # 시작시간을 기록한다\n",
    "print('Run : model training')\n",
    "for epoch in range(epoch_num):\n",
    "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "    if ((epoch + 1) % 100 == 0) or (epoch == epoch_num - 1):  # 100번째마다 또는 마지막 epoch인 경우\n",
    "        # 학습용데이터로 rmse오차를 구한다\n",
    "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
    "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
    "        train_error_summary.append(train_error)\n",
    "\n",
    "        # 테스트용데이터로 rmse오차를 구한다\n",
    "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
    "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
    "        test_error_summary.append(test_error)\n",
    "\n",
    "        # 현재 오류를 출력한다\n",
    "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch + 1, train_error, test_error,\n",
    "                                                                                 test_error - train_error))\n",
    "\n",
    "end_time = datetime.datetime.now()  # 종료시간을 기록한다\n",
    "elapsed_time = end_time - start_time  # 경과시간을 구한다\n",
    "print('elapsed_time:', elapsed_time)\n",
    "print('elapsed_time per epoch:', elapsed_time / epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2af42c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data_column_cnt: 3,output_data_column_cnt: 1,seq_length: 30,rnn_cell_hidden_dim: 20,forget_bias: 1.0,num_stacked_layers: 1,keep_prob: 1.0,epoch_num: 1000,learning_rate: 0.01"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_error_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,epoch_num:\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_num, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,learning_rate:\u001b[39m\u001b[38;5;124m'\u001b[39m, learning_rate, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,train_error:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtrain_error_summary\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,test_error:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_error_summary[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,min_test_error:\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmin(test_error_summary))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_error_summary' is not defined"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 출력\n",
    "print('input_data_column_cnt:', input_data_column_cnt, end='')\n",
    "print(',output_data_column_cnt:', output_data_column_cnt, end='')\n",
    "\n",
    "print(',seq_length:', seq_length, end='')\n",
    "print(',rnn_cell_hidden_dim:', rnn_cell_hidden_dim, end='')\n",
    "print(',forget_bias:', forget_bias, end='')\n",
    "print(',num_stacked_layers:', num_stacked_layers, end='')\n",
    "print(',keep_prob:', keep_prob, end='')\n",
    "\n",
    "print(',epoch_num:', epoch_num, end='')\n",
    "print(',learning_rate:', learning_rate, end='')\n",
    "\n",
    "print(',train_error:', train_error_summary[-1], end='')\n",
    "print(',test_error:', test_error_summary[-1], end='')\n",
    "print(',min_test_error:', np.min(test_error_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31182517",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_error_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 결과 그래프 출력\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_error_summary\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_error_summary, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch(x100)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_error_summary' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 그래프 출력\n",
    "plt.figure(1)\n",
    "plt.plot(train_error_summary, 'gold')\n",
    "plt.plot(test_error_summary, 'b')\n",
    "plt.xlabel('Epoch(x100)')\n",
    "plt.ylabel('Root Mean Square Error')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(testY, 'r')\n",
    "plt.plot(test_predict, 'b')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('AirTemp(Daily Mean)')\n",
    "plt.show()\n",
    "\n",
    "# sequence length만큼의 가장 최근 데이터를 슬라이싱한다\n",
    "recent_data = np.array([x[len(x) - seq_length:]])\n",
    "print(\"recent_data.shape:\", recent_data.shape)\n",
    "print(\"recent_data:\", recent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ec62361",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 내일 평균기온을 예측해본다\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241m.\u001b[39mrun(hypothesis, feed_dict\u001b[38;5;241m=\u001b[39m{X: recent_data})\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_predict\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_predict[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      5\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m reverse_min_max_scaling(temp_info, test_predict)  \u001b[38;5;66;03m# 기온값을 역정규화\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "# 내일 평균기온을 예측해본다\n",
    "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
    "\n",
    "print(\"test_predict\", test_predict[0])\n",
    "test_predict = reverse_min_max_scaling(temp_info, test_predict)  # 기온값을 역정규화\n",
    "print(\"Tomorrow's Daily Mean Air Temperature\", test_predict[0])  # 예측한 평균기온"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
